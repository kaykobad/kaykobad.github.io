<!DOCTYPE html>
<html lang='en'>
<!-- Template borrowed from Zikui Chai --> <!--https://zikuicai.github.io/ -->
<head>
  <!-- Google tag (gtag.js) -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-QM3WMX859K"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-QM3WMX859K');
  </script> -->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CKJ0KN02X2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-CKJ0KN02X2');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Permissions-Policy" content="interest-cohort=()">
  <!-- <meta http-equiv='cache-control' content='no-cache'> 
  <meta http-equiv='expires' content='0'> 
  <meta http-equiv='pragma' content='no-cache'> -->
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <title>Md Kaykobad Reza</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>

  <div class='js-off-canvas-container c-off-canvas-container'>
    
    <header class='c-header'>

      <div class='o-grid'>
        <div class='o-grid__col o-grid__col--full'>
          <div class='c-header__inner'>

            <div class='o-grid'>
              <div class='o-grid__col o-grid__col--2-4-s'>
                <div class='c-logo u-text-left'>
                  <a class='c-logo__link' href='index.html'>Md Kaykobad Reza</a>
                </div>
              </div>

              <div class='o-grid__col o-grid__col--2-4-s'>
                <div class='c-logo u-text-right'>
                  <a href='publications.html'><i>Publications</i></a> &nbsp / &nbsp
                  <a href='projects.html'><i>Projects</i></a> &nbsp / &nbsp
                  <a href='about-me.html'><i>About Me</i></a> &nbsp / &nbsp
                  <a href="files/Md_Kaykobad_Reza_Resume.pdf" class="image fit" target="_blank"><i>CV</i></a>
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>

    </header>

    <div class='o-wrapper'>

      
      <div class='o-grid'>
        <div class='o-grid__col'>

            <div class='c-content'>
              
              <img src='figs/reza-circle.png' class='c-post__image' alt='MD Kaykobad Reza' width="200">

              <p style="text-align: justify;"> 
                  Greetings,

                  <br>
                  I am Md Kaykobad Reza, a Ph.D. candidate in Computer Science and Engineering</a> at the <a href="https://www.ucr.edu/">University of California, Riverside</a>. I am working under the supervision of Professor <a href="https://intra.ece.ucr.edu/~sasif/">Dr. M. Salman Asif</a>. 
                  I completed my B.Sc. from <a href="https://www.buet.ac.bd/web/">Bangladesh University of Engineering and Technology</a> and M.Sc. from <a href="https://www.ucr.edu/">University of California, Riverside.</a> I am deeply grateful to <a href="https://scholar.google.com/citations?user=IUwFD9gAAAAJ&hl=en">Dr. M Sohel Rahman</a>, whose mentorship introduced me to the world of research and provided the foundational knowledge that has shaped my academic journey.
                  
                  <br><br>
                  <!-- My research interests broadly span the areas of multimodal machine learning, computer vision, natural language processing, and data mining. Currently, I am focusing on enhancing the robustness of multimodal machine learning models. This involves designing and adapting models and fusion strategies with specific goals in mind. Firstly, these models should be computationally efficient. Secondly, they must be capable of learning from noisy or poor-quality data. Lastly, they need to demonstrate resilience in scenarios involving missing, noisy, occluded, and unaligned modalities. -->
                  My research lies at the intersection of multimodal machine learning, computer vision, natural language processing, and data mining. I am particularly focused on enhancing the robustness of multimodal models, ensuring they remain <b>computationally efficient</b>, even with large-scale data. Effectively learn from <b>noisy, occluded, or low-quality data</b>. Adapt seamlessly to <b>missing, unaligned, or incomplete modalities</b> in real-world scenarios.
                  Through my work, I aim to develop more <b>reliable, adaptable, and cost-effective</b> multimodal learning solutions with applications in <b>autonomous systems, healthcare, surveillance, and more</b>.
                  
                  <br><br>
                  I had the privilege of gaining valuable professional experience at <a href="https://amazon.jobs/content/en/teams/devices-and-services/lab126">Amazon Lab126</a>, <a href="https://www.bkash.com/en/">bKash Limited</a> and <a href="https://research.samsung.com/srbd/">Samsung R&D Institute Bangladesh</a>. These roles enriched my technical expertise and deepened my understanding of the applicability of machine learning to solve real-world problems.
              </p>
              

              <p>
                <strong>News:</strong>
                <ul>
                  <li>[Jul. 2025] One paper on <a href="https://arxiv.org/abs/2501.17823">Multimodal Learning with Proxy Tokens</a> is accepted by <b>Asilomar 2025</b>.</li>
                  <li>[Jul. 2025] Tutorial on <a href="https://2025.ieeeicip.org/tutorials/#:~:text=Tutorial%209%3A%20(Half%2DDay)%20Foundations%20and%20Recent%20Trends%20in%20Robust%20Multimodal%20Learning">Robust Multimodal Learning</a> is accepted by <b>IEEE ICIP 2025</b>.</li>
                  <li>[Jun. 2025] Completed internship @ <a href="https://amazon.jobs/content/en/teams/devices-and-services/lab126">Amazon Lab126</a>.</li>
                  <li>[Jun. 2025] One paper on <a href="https://www.tandfonline.com/doi/full/10.1080/02626667.2025.2530120">Basin-wide Groundwater Level Forecasting</a> is accepted by <b>Hydrological Sciences Journal</b>.</li>
                  <li>[Jan. 2025] One preprint available on <a href="https://arxiv.org/abs/2501.17823">Robust Multimodal Learning via Cross-Modal Proxy Tokens</a>.</li>
                  <li>[Jan. 2025] Started internship @ <a href="https://amazon.jobs/content/en/teams/devices-and-services/lab126">Amazon Lab126</a>.</li>
                  <li>[Dec. 2024] Completed M.Sc. in CSE from <a href="https://www.ucr.edu/">UC Riverside</a>.</li>
                  <li>[Dec. 2024] One paper on <a href="https://ieeexplore.ieee.org/document/11022085">Social Network Analysis</a> is accepted by <b>ICCIT 2024</b>.</li></li>
                  <li>[Nov. 2024] Passed the Ph.D. qualifying examination and advanced to candidacy @ <a href="https://www.ucr.edu/">UC Riverside</a>.</li>
                  <li>[Oct. 2024] One paper on <a href="https://ieeexplore.ieee.org/document/10713849">Robust MML with Missing Modalities</a> is accepted by <b>IEEE TPAMI</b>.</li>
                  <li>[Oct. 2024] One preprint available on <a href="https://arxiv.org/abs/2410.03010">Robust Multimodal Learning with Masked Modality Projection</a>.</li>
                  <li>[Apr. 2024] One paper on <a href="https://ieeexplore.ieee.org/document/10502124">Multimodal Segmentation</a> is accepted by <b>IEEE OJSP</b>.</li>
                  <li>[Mar. 2024] One preprint available on <a href="https://arxiv.org/abs/2403.15937">Social Network Analysis</a>.</li>
                  <li>[Oct. 2023] One preprint available on <a href="https://arxiv.org/abs/2310.03986">Robust Multimodal Learning with Missing Modalities</a>.</li>
                  <li>[Sep. 2023] One preprint available on <a href="https://arxiv.org/abs/2309.04001">Multimodal Semantic and Material Segmentation</a>.</li>
                  <li>[Sep. 2022] Started Ph.D @ <a href="https://www.ucr.edu/">UC Riverside</a>.</li>
                  <li>[Aug. 2022] Left <a href="https://www.bkash.com/en">bKash Limited</a>.</li>
                  <li>[May. 2020] One paper on <a href="https://link.springer.com/chapter/10.1007/978-981-15-3607-6_47">Automatic Summarization</a> is accepted by <b>IJCCI 2019</b>.</li>
                  <li>[Jul. 2019] Joined <a href="https://www.bkash.com/en">bKash Limited<a href="https://www.bkash.com/en"></a>.</li>
                  <li>[Jul. 2019] Left <a href="https://research.samsung.com/srbd">Samsung R&D Institute Bangladesh</a>.</li>
                  <li>[May 2019] Joined <a href="https://research.samsung.com/srbd">Samsung R&D Institute Bangladesh</a>.</li>
                  <li>[April. 2019] Completed B.Sc. in CSE from <a href="https://www.buet.ac.bd/web/">Bangladesh University of Engineering and Technology</a>.</li>
                </ul>
              </p>

              <p><strong>Last Updated:</strong> July 12, 2025</p>
              
            </div>
          
        </div>
      </div>
      
    </div>

    <footer class='c-footer'>
      <div class='o-grid'>
        <div class='o-grid__col o-grid__col--full'>
    
          <ul class='o-plain-list c-social-nav u-text-center'>
            <li class='c-social-nav__item'>
              <a href='mailto:kaykobadreza@gmail.com' target='_blank'>
                <img src="figs/icon-email.svg", alt="Email", width="22">
              </a>
            </li>
            &nbsp
            <li class='c-social-nav__item'>
              <a href='https://github.com/kaykobad' target='_blank'>
                <img src="figs/icon-github.svg", alt="GitHub", width="24">
              </a>
            </li>
            &nbsp
            <li class='c-social-nav__item'>
              <a href='https://scholar.google.com/citations?user=GgXLwMsAAAAJ&hl=en' target='_blank'>
                <img src="figs/icon-google-scholar.svg", alt="Google Scholar", width="24">
              </a>
            </li>
            &nbsp
            <li class='c-social-nav__item'>
              <a href='https://www.linkedin.com/in/kaykobadreza/' target='_blank'>
                <img src="figs/icons8-linkedin.svg", alt="LinkedIn", width="24">
              </a>
            </li>
          </ul>
    
        </div>
      </div>
    </footer>

  </div>
</body>

</html>
